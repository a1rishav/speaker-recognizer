{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "#keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "import librosa.display\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ea1e6",
   "metadata": {},
   "source": [
    "## EDA and dataset curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/rishav/repo/ml/speaker-recognizer\"\n",
    "model_path = os.path.join(base_path, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f37f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data/shivam_shukla/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993a55c",
   "metadata": {},
   "source": [
    "**Visualize sound**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = os.path.join(base_path, \"data/shivam_shukla/TrainingAudio/Aadiksha-007/Aadiksha_1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(filename=sample_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cbe034",
   "metadata": {},
   "source": [
    "**Plot sound**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_audio, sr = librosa.load(sample_file)\n",
    "plt.figure(figsize=(15, 17))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "librosa.display.waveshow(sample_audio, alpha=0.5)\n",
    "plt.ylim((-1, 1))\n",
    "plt.title(\"Sample hindi audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/shivam_shukla/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path_and_speaker(data_dir):\n",
    "    speaker_name_and_ids = {}\n",
    "    speaker_counter = 0\n",
    "    file_path_and_speaker = {}\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        path = root.split(os.sep)\n",
    "        for file in files:\n",
    "            speaker, file_path = file.split(\"_\")[0].lower(), os.path.join(*path, file)            \n",
    "            if speaker not in speaker_name_and_ids:\n",
    "                speaker_counter += 1\n",
    "                speaker_name_and_ids[speaker] = speaker_counter\n",
    "            \n",
    "            speaker_id = speaker_name_and_ids[speaker]\n",
    "            file_path_and_speaker[file_path] = speaker_id\n",
    "            \n",
    "    \n",
    "    speaker_df = pd.DataFrame.from_dict(file_path_and_speaker, orient='index')\n",
    "    speaker_df['file_path'] = speaker_df.index\n",
    "    speaker_df.reset_index(drop=True, inplace=True)\n",
    "    speaker_df.rename(columns={0: 'speaker_id'}, inplace=True)\n",
    "    \n",
    "    return speaker_df, speaker_name_and_ids\n",
    "\n",
    "    \n",
    "speaker_df, speaker_name_and_ids = get_file_path_and_speaker(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''No. of speakers in the dataset : {len(speaker_df['speaker_id'].unique())}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be295b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speaker_name_and_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66d5c2e",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad6f75",
   "metadata": {},
   "source": [
    "### MFCCs + resemblyzer embeddings + ecapa-tdnn embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_classical_features(file_path):\n",
    "#     print(f'''File Path : {file_path}''')\n",
    "#     # Loads the audio file as a floating point time series and assigns the default sample rate\n",
    "#     # Sample rate is set to 22050 by default\n",
    "#     X, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "#     # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "#     mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    \n",
    "#     # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "#     stft = np.abs(librosa.stft(X))\n",
    "    \n",
    "#     # Computes a chromagram from a waveform or power spectrogram.\n",
    "#     chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    \n",
    "#     # Computes a mel-scaled spectrogram.\n",
    "#     mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    \n",
    "#     # Computes spectral contrast\n",
    "#     contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    \n",
    "#     # Computes the tonal centroid features (tonnetz)\n",
    "#     tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "#     sr=sample_rate).T,axis=0)\n",
    "#     return np.concatenate((mfccs, chroma, mel, contrast, tonnetz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran as a separate scipt\n",
    "\n",
    "# encoder = VoiceEncoder()\n",
    "# classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "# def extract_features(file_path):\n",
    "#     print(f'''File Path : {file_path}''')\n",
    "#     # Loads the audio file as a floating point time series and assigns the default sample rate\n",
    "#     # Sample rate is set to 22050 by default\n",
    "#     X, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "#     # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "#     mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    \n",
    "#     # resemblyzer embedding\n",
    "#     wav = preprocess_wav(file_path)\n",
    "#     resemblyzer_embedding = encoder.embed_utterance(wav)\n",
    "    \n",
    "#     # ecapa-tdnn embedding\n",
    "#     ecapa_embeddings = classifier.encode_batch(signal)\n",
    "#     ecapa_embeddings = np.array(embeddings)[0][0]\n",
    "    \n",
    "#     return np.concatenate((mfccs, resemblyzer_embedding, ecapa_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252927b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df = pd.read_pickle(os.path.join(base_path, \"embeddings/embedding_resem_ecapa_mfcc_2022-11-11.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf196d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df = speaker_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b68756",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bdff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f''' Length of features : {len(speaker_df['features'][0])} ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speaker_df), speaker_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c82e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speaker_df['speaker_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_speaker_df = speaker_df.groupby('speaker_id').agg({'file_path' : 'count'}).sort_values(by='file_path')\n",
    "single_speaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker with only one files\n",
    "speakers_with_1_file = single_speaker_df[single_speaker_df['file_path'] == 1].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df  = speaker_df[~speaker_df['speaker_id'].isin(speakers_with_1_file)]\n",
    "len(speaker_df['speaker_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c565c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speaker_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e95b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521572eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_col_to_multiple_cols(df, list_col_name):\n",
    "    df = df.reset_index(drop=True)\n",
    "    out_cols = [f'{list_col_name}_{col}' for col in range(len(df[list_col_name][0]))]\n",
    "\n",
    "    split_df = pd.DataFrame(df[list_col_name].tolist(), columns=out_cols)\n",
    "    df = pd.concat([df, split_df], axis=1)\n",
    "    df = df.drop(columns=[list_col_name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80fd57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df = split_list_col_to_multiple_cols(speaker_df, 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31899a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The most efficient way:\n",
    "\n",
    "1. Select last n columns\n",
    "\n",
    "df1 = df.iloc[:,-n:]\n",
    "\n",
    "2. Exclude last n columns\n",
    "\n",
    "df1 = df.iloc[:,:-n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0983a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df.iloc[:,-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc593bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc_cols = [f\"features_{counter}\"  for counter in range(448, 488)]\n",
    "# mfcc_cols = [\"speaker_id\", \"file_path\"] +  mfcc_cols\n",
    "# speaker_df = speaker_df[mfcc_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8959ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker_df = speaker_df.drop(columns=['file_path'])\n",
    "speaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df[speaker_df['speaker_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c383e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df_copy = speaker_df.copy()\n",
    "speaker_df_copy = speaker_df_copy.drop(columns=['file_path'])\n",
    "speaker_df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11693908",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_features = speaker_df_copy.iloc[:,-40:]\n",
    "mfcc_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(speaker_df_copy,\n",
    "                                                  speaker_df_copy['speaker_id'],\n",
    "                                                  stratify=speaker_df_copy['speaker_id'],\n",
    "                                                  test_size=0.20,\n",
    "                                                  random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train['speaker_id'].unique()), len(X_test['speaker_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87acca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e49c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_with_prefix(df, prefix):\n",
    "    return [col for col in df.columns if col.startswith(prefix)]\n",
    "    \n",
    "x_cols = get_cols_with_prefix(X_train, 'features')    \n",
    "X_train = X_train[x_cols]\n",
    "X_test = X_test[x_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265567d",
   "metadata": {},
   "source": [
    "**Normalize MFCC features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b96525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc cols\n",
    "cols = ['features_'+ str(counter) for counter in range(448, 488)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02cebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e41eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]\n",
    "\n",
    "X_train[cols] = ss.fit_transform(X_train[cols])\n",
    "X_test[cols] = ss.transform(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa166609",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.min().min(), X_train.max().max(), X_test.min().min(), X_test.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22847bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(X_train).isna().sum().sum())\n",
    "print(pd.DataFrame(X_test).isna().sum().sum())\n",
    "print(pd.DataFrame(y_train).isna().sum().sum())\n",
    "print(pd.DataFrame(y_test).isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_feature_size = 40\n",
    "n_classes = 100\n",
    "\n",
    "# initializer = tf.keras.initializers.GlorotNormal()\n",
    "model.add(Dense(64, input_shape=(input_feature_size,), activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.20))  \n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7991eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1034b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = 'model_mfcc.png'\n",
    "plot_model(model, to_file=dot_img_file, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=2000, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7884e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(235)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff1b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x = model.predict(X_test) \n",
    "classes_predicted = np.argmax(predict_x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaec704",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e389090",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"true_label\" : true_classes, \"predicted_label\" : classes_predicted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df = pred_df[pred_df['true_label'] == pred_df['predicted_label']]\n",
    "print(f'Accuracy : {len(matched_df)/ len(pred_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3689137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9597734",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_roc_auc_ovo = roc_auc_score(y_test, predict_x, multi_class=\"ovo\", average=\"macro\")\n",
    "weighted_roc_auc_ovo = roc_auc_score(\n",
    "    y_test, predict_x, multi_class=\"ovo\", average=\"weighted\"\n",
    ")\n",
    "macro_roc_auc_ovr = roc_auc_score(y_test, predict_x, multi_class=\"ovr\", average=\"macro\")\n",
    "weighted_roc_auc_ovr = roc_auc_score(\n",
    "    y_test, predict_x, multi_class=\"ovr\", average=\"weighted\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
    ")\n",
    "print(\n",
    "    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df['true_label'].values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc840d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(set(true_classes))):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predict_x[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), predict_x.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09384b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(roc_auc.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "# \n",
    "# colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#    plt.plot(\n",
    "#        fpr[i],\n",
    "#        tpr[i],\n",
    "#        color=color,\n",
    "#        lw=lw,\n",
    "#        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "#    )\n",
    "# \n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic to multiclass\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c31cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(true_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
